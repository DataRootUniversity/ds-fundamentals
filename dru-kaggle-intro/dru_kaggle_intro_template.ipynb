{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "dru_kaggle_intro_template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The challenge\n",
        "Your aim is to use the mobile characteristics data (battery capacity, resolution of the front camera, mobile mass, etc.) to predict the price range for each mobile in the test data."
      ],
      "metadata": {
        "id": "2eRI-yvAH2gk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The data\n",
        "To take a look at the competition data, click on the [Data tab](https://www.kaggle.com/c/dru-kaggle-intro/data) at the top of the competition page.\n",
        "There are three files: \n",
        "1. **train_mobile.csv**;\n",
        "2. **test_mobile.csv**;\n",
        "3. **sample_submission.csv**."
      ],
      "metadata": {
        "id": "CHplUAPjH2gn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Notebook\n",
        "\n",
        "You can create a Kaggle Notebook where you'll store all of your code or take a copy of this one. So you can use Kaggle Notebooks without having to install anything on your computer.\n",
        "\n",
        "If you want to create your notebook, you need to go to [the Code tab](https://www.kaggle.com/c/dru-kaggle-intro/code) on the competition page. Then, click on \"New Notebook\".\n",
        "\n",
        "![](https://dru.fra1.digitaloceanspaces.com/DS_Fundamentals/static/06_practical_ml/kaggle/dru_kaggle_intro/the_code_tab.png)"
      ],
      "metadata": {
        "id": "rXQOI_f6H2gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:14.999233Z",
          "iopub.execute_input": "2022-01-06T15:16:15.00044Z",
          "iopub.status.idle": "2022-01-06T15:16:15.03207Z",
          "shell.execute_reply.started": "2022-01-06T15:16:15.000273Z",
          "shell.execute_reply": "2022-01-06T15:16:15.031351Z"
        },
        "trusted": true,
        "id": "xBlytRKKH2go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows you where the competition data is stored so that you can load the files into the notebook."
      ],
      "metadata": {
        "id": "Rm-ea2JCH2gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Familiar With Your Data\n",
        "\n",
        "The first step in any machine learning project is to familiarise yourself with the data. Let's do this by using Pandas library."
      ],
      "metadata": {
        "id": "hHY8BtJYH2gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data\n",
        "# read and store data in **train** and **test** DataFrames\n",
        "train = pd.read_csv('/kaggle/input/dru-kaggle-intro/train_mobile.csv')\n",
        "test = pd.read_csv('/kaggle/input/dru-kaggle-intro/test_mobile.csv')\n",
        "\n",
        "# let's take a look at train data\n",
        "train.head(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:15.05806Z",
          "iopub.execute_input": "2022-01-06T15:16:15.058671Z",
          "iopub.status.idle": "2022-01-06T15:16:15.136954Z",
          "shell.execute_reply.started": "2022-01-06T15:16:15.058637Z",
          "shell.execute_reply": "2022-01-06T15:16:15.135845Z"
        },
        "trusted": true,
        "id": "HN64LsC6H2gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the train dataset contains 21 columns."
      ],
      "metadata": {
        "id": "__Tnq81MH2gr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring data"
      ],
      "metadata": {
        "id": "EkR7ulzHH2gs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring data is a step that allows us to understand the contents of the data, starting from the distribution, frequency, correlation and more.\n",
        "> `describe()` is used to display summary statistics for the numeric attributes of the dataset:"
      ],
      "metadata": {
        "id": "SApz3_2-H2gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print a summary of the train data\n",
        "train.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:15.139106Z",
          "iopub.execute_input": "2022-01-06T15:16:15.139447Z",
          "iopub.status.idle": "2022-01-06T15:16:15.205055Z",
          "shell.execute_reply.started": "2022-01-06T15:16:15.139404Z",
          "shell.execute_reply": "2022-01-06T15:16:15.204066Z"
        },
        "trusted": true,
        "id": "tt1-1eObH2gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset has categorical features, so we need to use data transformation because some dataset features are not numeric.\n",
        "> `info()` is used to get a concise summary of the data:"
      ],
      "metadata": {
        "id": "47YXKMqOH2gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:15.206803Z",
          "iopub.execute_input": "2022-01-06T15:16:15.207046Z",
          "iopub.status.idle": "2022-01-06T15:16:15.226792Z",
          "shell.execute_reply.started": "2022-01-06T15:16:15.207016Z",
          "shell.execute_reply": "2022-01-06T15:16:15.225725Z"
        },
        "trusted": true,
        "id": "IWQjHl4eH2gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the *Non-Null Count* of each column, it's evident that train data has some missing values in `clock_speed`, `sc_w`, `dual_sim`, and `four_g` columns. Also, we see that columns `blue`, `dual_sim`, `four_g`, `three_g`, `touch_screen`, and `wifi` have categorical values."
      ],
      "metadata": {
        "id": "RYrzsIS1H2gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list with categorical features\n",
        "cat_features_list = train.select_dtypes(include='object').columns.to_list()\n",
        "cat_features_list"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:15.228005Z",
          "iopub.execute_input": "2022-01-06T15:16:15.228222Z",
          "iopub.status.idle": "2022-01-06T15:16:15.237335Z",
          "shell.execute_reply.started": "2022-01-06T15:16:15.228195Z",
          "shell.execute_reply": "2022-01-06T15:16:15.236122Z"
        },
        "trusted": true,
        "id": "IsGKAbDzH2gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These columns only accept two unique values, \"no\" and \"yes\", so we can replace them with bool values 0 and 1, where 0 is \"no\", and 1 is \"yes\".\n",
        "\n",
        "> Converting categorical variables into numeric variables:"
      ],
      "metadata": {
        "id": "tLIRue_cH2gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_encode = ['blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi']\n",
        "\n",
        "for col in columns_to_encode:\n",
        "    \n",
        "    # encode columns for both train and test sets\n",
        "    train[f'{col}'] = train[f'{col}'].apply(lambda x: 1 if x == 'yes' else 0)\n",
        "    test[f'{col}'] = test[f'{col}'].apply(lambda x: 1 if x == 'yes' else 0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:15.239431Z",
          "iopub.execute_input": "2022-01-06T15:16:15.239667Z",
          "iopub.status.idle": "2022-01-06T15:16:15.2621Z",
          "shell.execute_reply.started": "2022-01-06T15:16:15.239637Z",
          "shell.execute_reply": "2022-01-06T15:16:15.261397Z"
        },
        "trusted": true,
        "id": "ejod-ErFH2gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data have missing values in columns `clock_speed`, `sc_w`, `dual_sim` and `four_g` that can cause inaccurate analysis. There are many ways to compensate for missing values in a dataset. Frequently used methods:\n",
        "* **mean** - works well with small numerical features, but doesnâ€™t factor in the correlations between features and is not very accurate, affecting the variance of the resulting dataset; \n",
        "* **mode** - works well with categorical features. It does not take into account the correlations and can introduce bias in the data by unwantedly assigning more labels to a specific category;\n",
        "* **interpolation** - it initiates a function that suits your data. This function can then be used to extrapolate values for missing data. It is more computationally expensive than the two methods above.\n",
        "\n",
        "> Below show the process of handling some missing values with the mean and mode of the column using the `fillna()` method:"
      ],
      "metadata": {
        "id": "q-enScLTH2gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['clock_speed'].fillna(train['clock_speed'].mean(), inplace=True)\n",
        "train['sc_w'].fillna(train['sc_w'].mean(), inplace=True)\n",
        "\n",
        "train['dual_sim'].fillna(train['dual_sim'].mode(), inplace=True)\n",
        "train['four_g'].fillna(train['four_g'].mode(), inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:15.263159Z",
          "iopub.execute_input": "2022-01-06T15:16:15.263719Z",
          "iopub.status.idle": "2022-01-06T15:16:15.273205Z",
          "shell.execute_reply.started": "2022-01-06T15:16:15.263685Z",
          "shell.execute_reply": "2022-01-06T15:16:15.272447Z"
        },
        "trusted": true,
        "id": "8PddgYgPH2gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding relationships\n"
      ],
      "metadata": {
        "id": "lVdZ8I7SH2gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's take a look at the correlation matrix for numerical features to see how the columns are related:"
      ],
      "metadata": {
        "id": "9LE65QHzH2gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation map\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "corr_mat_features_list = list(set(train.columns) - set(columns_to_encode))\n",
        "\n",
        "corr_mat = train[corr_mat_features_list].corr()\n",
        "f,ax = plt.subplots(figsize=(20,20))\n",
        "sns.heatmap(corr_mat, annot=True, linewidths=.5, fmt='.3f', ax=ax)\n",
        "plt.show"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:15.303397Z",
          "iopub.execute_input": "2022-01-06T15:16:15.304426Z",
          "iopub.status.idle": "2022-01-06T15:16:18.017013Z",
          "shell.execute_reply.started": "2022-01-06T15:16:15.304374Z",
          "shell.execute_reply": "2022-01-06T15:16:18.016272Z"
        },
        "trusted": true,
        "id": "ECHjiurhH2gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we see:\n",
        "* Our `price_range` has a strong correlation with `ram`;\n",
        "* `pc` has a positive correlation with `fc`;\n",
        "* `px_weight` and `px_height` are positive correlated;\n",
        "* `sc_w` and `sc_h` are positively correlated."
      ],
      "metadata": {
        "id": "Hxhbr9lgH2gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's sort price_range correlation\n",
        "corr_mat.sort_values(by=[\"price_range\"], ascending=False).iloc[0].sort_values(ascending=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:18.018636Z",
          "iopub.execute_input": "2022-01-06T15:16:18.019588Z",
          "iopub.status.idle": "2022-01-06T15:16:18.029525Z",
          "shell.execute_reply.started": "2022-01-06T15:16:18.019549Z",
          "shell.execute_reply": "2022-01-06T15:16:18.028548Z"
        },
        "trusted": true,
        "id": "H110OSJSH2gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how ram affects price_range\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.title('The Effect of RAM capacity on Price Range')\n",
        "sns.barplot(x = 'price_range',y = 'ram',data = train, )\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:18.030929Z",
          "iopub.execute_input": "2022-01-06T15:16:18.031538Z",
          "iopub.status.idle": "2022-01-06T15:16:18.38518Z",
          "shell.execute_reply.started": "2022-01-06T15:16:18.03149Z",
          "shell.execute_reply": "2022-01-06T15:16:18.384208Z"
        },
        "trusted": true,
        "id": "qerRuVcYH2gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The more RAM, the more expensive the phone."
      ],
      "metadata": {
        "id": "uT2MsBPwH2g0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking outliers\n",
        "Outliers can markedly affect our models and can be a valuable source of information, providing us insights into specific behaviours."
      ],
      "metadata": {
        "id": "xxuZWAwPH2g0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier analysis of non-categorical data\n",
        "fig, ax = plt.subplots(ncols=2, nrows=7, figsize=(12,24))\n",
        "\n",
        "features_to_check_outliers = ['battery_power', 'clock_speed', 'fc',\n",
        "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
        "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']\n",
        "\n",
        "for i, col in enumerate(features_to_check_outliers):\n",
        "    sns.boxplot(x = train[f'{col}'], ax = ax[int(i % len(features_to_check_outliers) / 2) , i % 2])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:18.387721Z",
          "iopub.execute_input": "2022-01-06T15:16:18.388552Z",
          "iopub.status.idle": "2022-01-06T15:16:20.286517Z",
          "shell.execute_reply.started": "2022-01-06T15:16:18.388506Z",
          "shell.execute_reply": "2022-01-06T15:16:20.28535Z"
        },
        "trusted": true,
        "id": "pjeJVMbYH2g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a few outliers in `fc` and `px_height` only. *If we were solving a regression problem, then we would need to pay special attention to outliers in the data.*"
      ],
      "metadata": {
        "id": "NjfdJUI1H2g1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardization"
      ],
      "metadata": {
        "id": "0rZkDPyaH2g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature scaling for continuous variables\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "numerical_features_list = ['battery_power', 'clock_speed', 'fc',\n",
        "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
        "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']\n",
        "\n",
        "train[numerical_features_list]= sc.fit_transform(train[numerical_features_list])\n",
        "test[numerical_features_list] = sc.fit_transform(test[numerical_features_list])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:20.288498Z",
          "iopub.execute_input": "2022-01-06T15:16:20.288843Z",
          "iopub.status.idle": "2022-01-06T15:16:20.435887Z",
          "shell.execute_reply.started": "2022-01-06T15:16:20.288799Z",
          "shell.execute_reply": "2022-01-06T15:16:20.435016Z"
        },
        "trusted": true,
        "id": "YI65MO_BH2g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the training and testing dataset"
      ],
      "metadata": {
        "id": "VkHGlxVMH2g2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# splitting of data\n",
        "train_df = train.copy()\n",
        "\n",
        "X = train_df.drop('price_range',axis=1)\n",
        "y = train_df['price_range']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:20.437197Z",
          "iopub.execute_input": "2022-01-06T15:16:20.43746Z",
          "iopub.status.idle": "2022-01-06T15:16:20.508601Z",
          "shell.execute_reply.started": "2022-01-06T15:16:20.437428Z",
          "shell.execute_reply": "2022-01-06T15:16:20.50778Z"
        },
        "trusted": true,
        "id": "Ebs34l15H2g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Model\n",
        "\n",
        "You will use the scikit-learn library to create your models. Scikit-learn is easily the most popular library for modelling data types typically stored in DataFrames.\n",
        "\n",
        "The steps to building and using a model are:\n",
        "\n",
        "1. **Defining** the type of model.\n",
        "2. **Fit**: Capture patterns from provided data.\n",
        "3. **Predict**: Predicting target value.\n",
        "4. **Evaluate**: Determine how accurate the model's predictions are.\n",
        "\n",
        "Below is an example of defining a KNeighbours Classifier model with scikit-learn and fitting it with the features and target variable."
      ],
      "metadata": {
        "id": "61znuVCgH2g3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# defining model\n",
        "classifier = KNeighborsClassifier()\n",
        "\n",
        "# fit the model\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predicting X_val\n",
        "y_pred_knn = classifier.predict(X_val)\n",
        "\n",
        "# evaluating\n",
        "print(classification_report(y_val, y_pred_knn))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:20.509836Z",
          "iopub.execute_input": "2022-01-06T15:16:20.510074Z",
          "iopub.status.idle": "2022-01-06T15:16:20.7104Z",
          "shell.execute_reply.started": "2022-01-06T15:16:20.510043Z",
          "shell.execute_reply": "2022-01-06T15:16:20.709225Z"
        },
        "trusted": true,
        "id": "xJelGNaNH2g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# visualizing the confusion matrix\n",
        "cm = confusion_matrix(y_val, y_pred_knn)\n",
        "# label the confusion matrix  \n",
        "conf_matrix=pd.DataFrame(data = cm, \n",
        "                         columns=[\"0 price_range\", \"1 price_range\", \"2 price_range\", \"3 price_range\"], \n",
        "                         index=[\"0 price_range\", \"1 price_range\", \"2 price_range\", \"3 price_range\"])\n",
        "# plot a heatmap\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"YlGnBu\")\n",
        "plt.title(\"Confusion Matrix for KNN\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:20.711837Z",
          "iopub.execute_input": "2022-01-06T15:16:20.71208Z",
          "iopub.status.idle": "2022-01-06T15:16:21.009278Z",
          "shell.execute_reply.started": "2022-01-06T15:16:20.712051Z",
          "shell.execute_reply": "2022-01-06T15:16:21.008209Z"
        },
        "trusted": true,
        "id": "lzU9bVepH2g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the classification accuracy is too poor. Let's try another classification model:"
      ],
      "metadata": {
        "id": "pzOLuQFWH2g5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# defining model\n",
        "mlp = MLPClassifier(learning_rate_init=0.005, alpha=1e-3, tol=1e-1, \n",
        "                    early_stopping=True, validation_fraction=0.2, random_state=42)\n",
        "\n",
        "# fit the model\n",
        "mlp.fit(X_train,y_train)\n",
        "\n",
        "# predicting X_val\n",
        "y_pred_mlp = mlp.predict(X_val)\n",
        "\n",
        "# evaluating\n",
        "print(classification_report(y_val, y_pred_mlp))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:21.011103Z",
          "iopub.execute_input": "2022-01-06T15:16:21.011341Z",
          "iopub.status.idle": "2022-01-06T15:16:23.674321Z",
          "shell.execute_reply.started": "2022-01-06T15:16:21.011311Z",
          "shell.execute_reply": "2022-01-06T15:16:23.673393Z"
        },
        "trusted": true,
        "id": "cbQfE-TeH2g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the confusion matrix\n",
        "cm = confusion_matrix(y_val, y_pred_mlp)\n",
        "# label the confusion matrix  \n",
        "conf_matrix=pd.DataFrame(data = cm, \n",
        "                         columns=[\"0 price_range\", \"1 price_range\", \"2 price_range\", \"3 price_range\"], \n",
        "                         index=[\"0 price_range\", \"1 price_range\", \"2 price_range\", \"3 price_range\"])\n",
        "# plot a heatmap\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"YlGnBu\")\n",
        "plt.title(\"Confusion matrix for MLPClassifier\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:23.676601Z",
          "iopub.execute_input": "2022-01-06T15:16:23.677485Z",
          "iopub.status.idle": "2022-01-06T15:16:24.028481Z",
          "shell.execute_reply.started": "2022-01-06T15:16:23.677432Z",
          "shell.execute_reply": "2022-01-06T15:16:24.027813Z"
        },
        "trusted": true,
        "id": "j4eFmn1PH2g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy has improved, but it is still not the best result. Your task will be to find and choose the best model for the given dataset. Try to check the accuracy of the classifiers you are familiar with or try to improve the ones already mentioned."
      ],
      "metadata": {
        "id": "B_63f2_DH2g7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using best trained algorithm"
      ],
      "metadata": {
        "id": "jPSeBcvmH2g8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove 'index' column\n",
        "test_df = test.copy()\n",
        "test_df = test_df.drop('index', axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:24.030988Z",
          "iopub.execute_input": "2022-01-06T15:16:24.031456Z",
          "iopub.status.idle": "2022-01-06T15:16:24.037063Z",
          "shell.execute_reply.started": "2022-01-06T15:16:24.031422Z",
          "shell.execute_reply": "2022-01-06T15:16:24.036449Z"
        },
        "trusted": true,
        "id": "XckOJkz6H2g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction on the test set\n",
        "predicted_price_range = mlp.predict(test_df)\n",
        "predicted_price_range"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:16:24.038636Z",
          "iopub.execute_input": "2022-01-06T15:16:24.039083Z",
          "iopub.status.idle": "2022-01-06T15:16:24.091026Z",
          "shell.execute_reply.started": "2022-01-06T15:16:24.039052Z",
          "shell.execute_reply": "2022-01-06T15:16:24.089844Z"
        },
        "trusted": true,
        "id": "YTbAM7XYH2g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission\n",
        "Our goal: is to find patterns in **train_mobile.csv** that help us predict \"price_range\" for each mobile in **test_mobile.csv**."
      ],
      "metadata": {
        "id": "sYFcM2w4H2g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating submission file\n",
        "submission = pd.DataFrame({'index': test['index'],\n",
        "                           'price_range': predicted_price_range})\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-06T15:17:57.27459Z",
          "iopub.execute_input": "2022-01-06T15:17:57.274903Z",
          "iopub.status.idle": "2022-01-06T15:17:57.283573Z",
          "shell.execute_reply.started": "2022-01-06T15:17:57.274869Z",
          "shell.execute_reply": "2022-01-06T15:17:57.282802Z"
        },
        "trusted": true,
        "id": "G4LzHMPPH2g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Click on the \"**Save Version**\" button in the top right corner of your notebook.\n",
        "* Select \"**Save and Run All**\" option. If it is not, then click on the \"**Save**\" button.\n",
        "* This generates a window in the bottom left corner of the notebook. After it has finished running, click on the number to the right of the \"**Save Version**\" button. This pulls up a list of versions on the right of the screen. Click on the ellipsis (...) to the right of the most recent version, and select **Open in Viewer**. This brings you into view mode on the same page. You will need to scroll down to get back to these instructions.\n",
        "* Click on the **Data** tab on the right of the screen. Then, click on the \"**Submit**\" button to submit your results.\n",
        "![image.png](https://dru.fra1.digitaloceanspaces.com/DS_Fundamentals/static/06_practical_ml/kaggle/dru_kaggle_intro/submission.png\n",
        ")\n"
      ],
      "metadata": {
        "id": "_oqYCi5XH2g9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "># Your turn!\n",
        "\n",
        ">Now try to improve the quality of price_range classification for this dataset [yourself](https://www.kaggle.com/c/dru-kaggle-intro/code)ðŸ’ª\n"
      ],
      "metadata": {
        "id": "1YkwsHspH2g-"
      }
    }
  ]
}